{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\oscarros\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\oscarros\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    import nltk\n",
    "except ImportError:\n",
    "    print(\"NLTK library not installed, installing now...\")\n",
    "    %pip install nltk\n",
    "    import nltk\n",
    "\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "from nltk.tag.mapping import map_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for reading and formatting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadDocument(filename):\n",
    "    dataSet = []\n",
    "    with open(filename, 'r') as file:\n",
    "        content = file.read()\n",
    "        content = content.replace('\\n', ' ')\n",
    "        content = content.split(' ')\n",
    "\n",
    "        for token in content:\n",
    "            if token != '':\n",
    "                word, posTag = token.split('_')\n",
    "                word = word.lower()\n",
    "                dataSet.append((word, posTag))\n",
    "    return dataSet\n",
    "\n",
    "def ReadTagTranslator(filename):\n",
    "    \"\"\"\n",
    "    Assigns each brown tag to a universal tag in a dictionary\n",
    "    \"\"\"\n",
    "    tagTranslator = {}\n",
    "    with open(filename, 'r') as file:\n",
    "        content = file.read()\n",
    "        content = content.split('\\n')\n",
    "        for line in content:\n",
    "            if line != '':\n",
    "                if len(line.split('\\t')) == 2:\n",
    "                    brownTag, universalTag = line.split('\\t')\n",
    "                    tagTranslator[brownTag] = universalTag\n",
    "                else:\n",
    "                    # Handels a special (single) case where the split did not work as expected\n",
    "                    rest = line.split('\\t')\n",
    "                    tagTranslator[rest[0]] = rest[-1]\n",
    "    return tagTranslator\n",
    "\n",
    "def ConvertTags(dataSet, tagTranslator):\n",
    "    \"\"\"\n",
    "    Convert all tags in the dataset to universal tags\n",
    "    \"\"\"\n",
    "    convertedDataSet = []\n",
    "    for word, posTag in dataSet:\n",
    "        if posTag in tagTranslator:\n",
    "            convertedDataSet.append((word, tagTranslator[posTag]))\n",
    "        else:\n",
    "            convertedDataSet.append((word, posTag))\n",
    "    return convertedDataSet\n",
    "\n",
    "def SplitData(dataSet, splitRatio=0.8):\n",
    "    splitIndex = int(len(dataSet) * splitRatio)\n",
    "    trainingData = dataSet[:splitIndex]\n",
    "    testData = dataSet[splitIndex:]\n",
    "    return trainingData, testData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement perceptron tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunTagger(dataSet):\n",
    "    \"\"\"\n",
    "    Loads a pretrained perceptron tagger and tags the given dataset.\n",
    "    Reformats the dataset by isolating the words from their tags before submitting it to the tagger.\n",
    "    \"\"\"\n",
    "    tagger = PerceptronTagger(load=True)\n",
    "    tokens = [token for token, tag in dataSet]\n",
    "    assinedTags = tagger.tag(tokens)\n",
    "    return assinedTags\n",
    "\n",
    "def TranslateAssignedTags(assignedTags, source='en-ptb'):\n",
    "    \"\"\"\n",
    "    Translates the tags assigned by the tagger to universal tags\n",
    "    \"\"\"\n",
    "    translatedDataSet = []\n",
    "    for word, tag in assignedTags:\n",
    "        universalTag = map_tag(source, 'universal', tag)\n",
    "        translatedDataSet.append((word, universalTag))\n",
    "    return translatedDataSet\n",
    "\n",
    "def ComputeAccuracy(dataSet, assignedTags):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the tagger\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    totalNumberOfWords = len(dataSet)\n",
    "\n",
    "    for (word, tag), (word, assignedTag) in zip(dataSet, assignedTags):\n",
    "        if tag == assignedTag:\n",
    "            correct += 1\n",
    "    return correct / totalNumberOfWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of pretrained perceptron\n",
      " > Test data set: 87.55 %\n"
     ]
    }
   ],
   "source": [
    "# Read file and preprocess data\n",
    "dataSet = ReadDocument(\"BrownCorpus.txt\")\n",
    "brownToUniversalMappings = ReadTagTranslator(\"BrownToUniversalTagMap.txt\")\n",
    "dataSet = ConvertTags(dataSet, brownToUniversalMappings)\n",
    "trainingData, testData = SplitData(dataSet)\n",
    "\n",
    "# Run tagger and compute accuracy\n",
    "taggedTestData = RunTagger(testData)\n",
    "translatedTestData = TranslateAssignedTags(taggedTestData)\n",
    "taggingAccuracy = ComputeAccuracy(testData, translatedTestData)\n",
    "\n",
    "print(f'Accuracy of pretrained perceptron')\n",
    "print(f' > Test data set: {100*taggingAccuracy:.2f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
